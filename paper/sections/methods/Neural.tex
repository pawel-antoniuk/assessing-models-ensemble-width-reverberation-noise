\section{Neural-Network-Based Method}
\label{sec:methods:neural}

While the auditory-model-based method attempts to mimic human hearing mechanisms, the neural network approach takes advantage of Convolutional Neural Networks (CNNs) and their ability to automatically learn relevant features from spectral representations of audio signals. In contrast to the~auditory-model-based approach, the neural network method uses a basic feature extraction technique based on magnitude spectrograms \cite{antoniuk_estimating_2024}.

A Hamming window of 40 ms with an~overlap of 20 ms is applied, resulting in 349 time frames extracted for each binaural input signal. For each time frame, the Fast Fourier Transform (FFT) is applied. The magnitudes of its output are aggregated into 64 linearly spaced frequency bands ranging from 100 Hz to 16 kHz, effectively creating a spectrogram with dimensions $349 \times 64$. This process is performed separately for the left and right channels, producing a pair of spectrograms that are then used in the neural network to simultaneously estimate two ensemble parameters: width and location. However, only ensemble width is considered in this study.

In the next step, the spectrograms are input into a two-dimensional CNN model to estimate the ensemble width, effectively treating the spectrograms as visual data. The network's topology is based on the AlexNet model introduced by Krizhevsky et al.~\cite{krizhevsky_imagenet_2017}. The input layer is followed by five convolutional units, each consisting of a ReLU-activated 2D convolution layer with a~$2 \times 2$ filter size, followed by a~max pooling layer of size $2 \times 3$ or $2 \times 2$. The number of convolutional filters in each layer is 32, 64, 128, and 256, respectively. Following these layers, a global average pooling layer is applied to reduce overfitting \cite{lin_network_2013}. The next stage consists of four fully connected layers with ReLU activation, reducing the activation map's dimensions from 256 to 6. Finally, two parallel fully connected layers with linear activation are used to predict the ensemble parameters; one outputs the~ensemble width, and the other outputs the~ensemble location.

In total, this topology resulted in a model with 216,562 learning parameters. The model was trained using a Monte Carlo cross-validation procedure with 10 repetitions and an~early-stopping validation subset. For further details, see~\cite{antoniuk_estimating_2024}.
